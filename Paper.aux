\relax 
\citation{NovelConnectionist,Kurzweilinterview}
\citation{NIPS2008_3449,Rumelhart:ExploMicroStructure}
\citation{website:dataeverywhere}
\citation{Kussul_improvedmethod}
\citation{SVMSpeedPatternReg,usinganalytic}
\citation{FastKNNClusterBasedTrees,MNISTHandWritten}
\citation{Lecun98gradient-basedlearning}
\citation{MultiColummn}
\citation{Lecun98gradient-basedlearning}
\citation{IGotMoreData,WhenItSeem}
\citation{WhenItSeem}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\newlabel{sec:introduction@cref}{{[section][1][]I}{1}}
\citation{perceptron}
\citation{Aizenberg07multilayerfeedforward}
\citation{CybenkoApproxSidmoid}
\citation{FundermentalANN}
\citation{ZhangANNForecast}
\citation{pittman2008handwriting}
\citation{buscema1998back}
\citation{Leonard1990337ImproveBPNN,Magoulas:1999:ImproveConvergenceBP,Riedmiller93adirect}
\citation{dennis1977quasi}
\citation{grippo1997globally}
\citation{wei2000new}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background and Related Work}{2}}
\newlabel{sec:background}{{II}{2}}
\newlabel{sec:background@cref}{{[section][2][]II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Main Concepts}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0a}Perceptron}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Multilayer Perceptron\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure:MLP}{{1}{2}}
\newlabel{figure:MLP@cref}{{[figure][1][]1}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0b}Multilayer Perceptron}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0c}Artificial Neural Networks}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0d}Back-Propagation Neural Networks}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0e}Nonlinear conjugate gradient method using Polack-Ribiere formula}{2}}
\citation{FastKNNClusterBasedTrees}
\citation{MNISTHandWritten}
\citation{Lecun98gradient-basedlearning}
\citation{Geman:1992:NNBBiasDilemma,BiasVarianceDecomposition}
\citation{WhenItSeem}
\citation{WhenItSeem}
\citation{IGotMoreData}
\citation{IGotMoreData}
\citation{Meng94}
\citation{IGotMoreData}
\citation{IGotMoreData}
\citation{Hornik_Universal_appro}
\citation{grippo1997globally}
\citation{Polak1969}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0f}MNIST Database}{3}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0g}The Bias-Variance Trade-Off}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Related Work}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Experiment}{3}}
\newlabel{sec:Experiment}{{III}{3}}
\newlabel{sec:Experiment@cref}{{[section][3][]III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}The Classifier}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}The database}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Training Sets}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Training Procedure}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Class Proportion Variance vs. Training Set\relax }}{4}}
\newlabel{figure:ClassProportionVarianceVsTrainingSet}{{2}{4}}
\newlabel{figure:ClassProportionVarianceVsTrainingSet@cref}{{[figure][2][]2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3a}{\ignorespaces Accuracy vs. Hidden layer size\relax }}{4}}
\newlabel{figure:AccuracyHLSizeA}{{3a}{4}}
\newlabel{figure:AccuracyHLSizeA@cref}{{[figure][1][]3a}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Result}{4}}
\newlabel{sec:Result}{{IV}{4}}
\newlabel{sec:Result@cref}{{[section][4][]IV}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Class Proportion vs. Training Set\relax }}{5}}
\newlabel{table:ClassProportionVsTrainingSet}{{I}{5}}
\newlabel{table:ClassProportionVsTrainingSet@cref}{{[table][1][]I}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3b}{\ignorespaces Accuracy vs. Hidden layer size\relax }}{5}}
\newlabel{figure:AccuracyHLSizeB}{{3b}{5}}
\newlabel{figure:AccuracyHLSizeB@cref}{{[figure][2][]3b}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Confusion matrix\relax }}{5}}
\newlabel{figure:MatrixConfusion}{{4}{5}}
\newlabel{figure:MatrixConfusion@cref}{{[figure][4][]4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Most common confusions\relax }}{5}}
\newlabel{figure:SomeConfusion}{{5}{5}}
\newlabel{figure:SomeConfusion@cref}{{[figure][5][]5}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6a}{\ignorespaces Accuracy vs. Training set size\relax }}{5}}
\newlabel{figure:AccuracyTSSizeA}{{6a}{5}}
\newlabel{figure:AccuracyTSSizeA@cref}{{[figure][1][]6a}{5}}
\citation{FastKNNClusterBasedTrees,MNISTHandWritten}
\citation{FastKNNClusterBasedTrees}
\@writefile{lof}{\contentsline {figure}{\numberline {6b}{\ignorespaces Accuracy vs. Training set size\relax }}{6}}
\newlabel{figure:AccuracyTSSizeB}{{6b}{6}}
\newlabel{figure:AccuracyTSSizeB@cref}{{[figure][2][]6b}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Neural networks that do not perform best on test set after full-set training\relax }}{6}}
\newlabel{figure:fig2ilu}{{7}{6}}
\newlabel{figure:fig2ilu@cref}{{[figure][7][]7}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}}
\newlabel{sec:conclusion}{{V}{6}}
\newlabel{sec:conclusion@cref}{{[section][5][]V}{6}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,mybib}
\bibcite{NovelConnectionist}{1}
\bibcite{Kurzweilinterview}{2}
\bibcite{NIPS2008_3449}{3}
\bibcite{Rumelhart:ExploMicroStructure}{4}
\bibcite{website:dataeverywhere}{5}
\bibcite{Kussul_improvedmethod}{6}
\bibcite{SVMSpeedPatternReg}{7}
\bibcite{usinganalytic}{8}
\bibcite{FastKNNClusterBasedTrees}{9}
\bibcite{MNISTHandWritten}{10}
\bibcite{Lecun98gradient-basedlearning}{11}
\bibcite{MultiColummn}{12}
\bibcite{IGotMoreData}{13}
\bibcite{WhenItSeem}{14}
\bibcite{perceptron}{15}
\bibcite{Aizenberg07multilayerfeedforward}{16}
\bibcite{CybenkoApproxSidmoid}{17}
\bibcite{FundermentalANN}{18}
\bibcite{ZhangANNForecast}{19}
\bibcite{pittman2008handwriting}{20}
\bibcite{buscema1998back}{21}
\bibcite{Leonard1990337ImproveBPNN}{22}
\bibcite{Magoulas:1999:ImproveConvergenceBP}{23}
\bibcite{Riedmiller93adirect}{24}
\bibcite{dennis1977quasi}{25}
\bibcite{grippo1997globally}{26}
\bibcite{wei2000new}{27}
\bibcite{Geman:1992:NNBBiasDilemma}{28}
\bibcite{BiasVarianceDecomposition}{29}
\bibcite{Meng94}{30}
\bibcite{Hornik_Universal_appro}{31}
\bibcite{Polak1969}{32}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Performance on test set of two different models\relax }}{7}}
\newlabel{table:perform}{{II}{7}}
\newlabel{table:perform@cref}{{[table][2][]II}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
\@writefile{toc}{\contentsline {section}{Appendix}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8a}{\ignorespaces Accuracy vs. Training set size\relax }}{8}}
\newlabel{figure:ATSS_A}{{8a}{8}}
\newlabel{figure:ATSS_A@cref}{{[figure][1][2147483647]8a}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8b}{\ignorespaces Accuracy vs. Training set size\relax }}{8}}
\newlabel{figure:ATSS_B}{{8b}{8}}
\newlabel{figure:ATSS_B@cref}{{[figure][2][2147483647]8b}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8c}{\ignorespaces Accuracy vs. Training set size\relax }}{9}}
\newlabel{figure:ATSS_C}{{8c}{9}}
\newlabel{figure:ATSS_C@cref}{{[figure][3][2147483647]8c}{9}}
